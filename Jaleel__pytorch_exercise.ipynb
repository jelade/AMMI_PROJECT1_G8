{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "3ry0UiyuXKAY",
        "nkbOB_6EX9ky",
        "tmT8aLwCYe4Z"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jelade/AMMI_PROJECT1_G8/blob/main/Jaleel__pytorch_exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction"
      ],
      "metadata": {
        "id": "NqhY6Cb_W-gV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The objective of this session is to practice with basic tensor manipulations in pytorch, to understand the\n",
        "relation between a tensor and its underlying storage, and get a sense of the efficiency of tensor-based\n",
        "computation compared to their equivalent python iterative implementations"
      ],
      "metadata": {
        "id": "VYQOOU_nXDhu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "c6dhBdHDheYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1- Multiple views of a storage"
      ],
      "metadata": {
        "id": "3ry0UiyuXKAY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate the following matrix with no python loop"
      ],
      "metadata": {
        "id": "CNXRTG2PXrbG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\n",
        "\\begin{bmatrix}\n",
        "1 & 2 & 1 & 1 & 1 & 1 & 2 & 1 & 1 & 1 & 1 & 2 & 1\\\\\n",
        "2 & 2 & 2 & 2 & 2 & 2 & 2 & 2 & 2 & 2 & 2 & 2 & 2\\\\\n",
        "1 & 2 & 1 & 1 & 1 & 1 & 2 & 1 & 1 & 1 & 1 & 2 & 1\\\\\n",
        "1 & 2 & 1 & 3 & 3 & 1 & 2 & 1 & 3 & 3 & 1 & 2 & 1\\\\\n",
        "1 & 2 & 1 & 3 & 3 & 1 & 2 & 1 & 3 & 3 & 1 & 2 & 1\\\\\n",
        "1 & 2 & 1 & 1 & 1 & 1 & 2 & 1 & 1 & 1 & 1 & 2 & 1\\\\\n",
        "2 & 2 & 2 & 2 & 2 & 2 & 2 & 2 & 2 & 2 & 2 & 2 & 2\\\\\n",
        "1 & 2 & 1 & 1 & 1 & 1 & 2 & 1 & 1 & 1 & 1 & 2 & 1\\\\\n",
        "1 & 2 & 1 & 3 & 3 & 1 & 2 & 1 & 3 & 3 & 1 & 2 & 1\\\\\n",
        "1 & 2 & 1 & 3 & 3 & 1 & 2 & 1 & 3 & 3 & 1 & 2 & 1\\\\\n",
        "1 & 2 & 1 & 1 & 1 & 1 & 2 & 1 & 1 & 1 & 1 & 2 & 1\\\\\n",
        "2 & 2 & 2 & 2 & 2 & 2 & 2 & 2 & 2 & 2 & 2 & 2 & 2\\\\\n",
        "1 & 2 & 1 & 1 & 1 & 1 & 2 & 1 & 1 & 1 & 1 & 2 & 1\\\\\n",
        "\\end{bmatrix}\n",
        "$"
      ],
      "metadata": {
        "id": "1ZDdG6ikXfwT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hint**:  Use `torch.full`, and the slicing operator."
      ],
      "metadata": {
        "id": "hlhpUjWlXz_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w = torch.full((13,13),1)\n",
        "w[(1,-2),:] = 2\n",
        "w[:,(1,-2)] = 2\n",
        "w[:,6] = 2\n",
        "w[6,:] = 2\n",
        "w[3:5,3:5]= 3\n",
        "w[-4:-2,-4:-2] = 3\n",
        "w[3:5,-4:-2] = 3\n",
        "w[-5:-3,3:5]= 3"
      ],
      "metadata": {
        "id": "kiktWl1kgx5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "w"
      ],
      "metadata": {
        "id": "zM132KzPiUrF",
        "outputId": "b977ebcc-36db-4ccc-e274-f0ac6572c328",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1],\n",
              "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
              "        [1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1],\n",
              "        [1, 2, 1, 3, 3, 1, 2, 1, 1, 3, 3, 2, 1],\n",
              "        [1, 2, 1, 3, 3, 1, 2, 1, 1, 3, 3, 2, 1],\n",
              "        [1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1],\n",
              "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
              "        [1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1],\n",
              "        [1, 2, 1, 3, 3, 1, 2, 1, 1, 1, 1, 2, 1],\n",
              "        [1, 2, 1, 3, 3, 1, 2, 1, 1, 3, 3, 2, 1],\n",
              "        [1, 2, 1, 1, 1, 1, 2, 1, 1, 3, 3, 2, 1],\n",
              "        [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
              "        [1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2- Eigen decomposition"
      ],
      "metadata": {
        "id": "nkbOB_6EX9ky"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Without using python loops, create a square matrix $M$ (a 2d tensor) of dimension 20 Ã— 20, filled with\n",
        "random Gaussian coefficients and  a diagonal matrix $D$ \n"
      ],
      "metadata": {
        "id": "1QvpIGUHYGfX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$D = \\begin{bmatrix} 1 & 0 & 0 & \\dots & 0 \\\\ 0 & 2 & 0 & \\dots & 0 \\\\ 0 & 0 & 3 & \\dots & 0 \\\\ \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\ 0 & 0 & 0 & \\dots & 20 \\end{bmatrix}$"
      ],
      "metadata": {
        "id": "vVfUV91PbpLH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute the eigen values of:"
      ],
      "metadata": {
        "id": "mDBEgquSgUIu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\\begin{equation*}\n",
        "M^{-1} D\n",
        " M\n",
        "\\end{equation*}"
      ],
      "metadata": {
        "id": "xsWTXAQ4Z-Ym"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hint**: Use `torch.empty`, `torch.normal_`, `torch.arange`, `torch.diag`, `torch.mm`, `torch.inverse`,\n",
        "and `torch.linalg.eig`."
      ],
      "metadata": {
        "id": "Faxx2RibYHdl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "M = torch.randn((20,20))\n",
        "D = torch.arange(1,len(M)+1)\n",
        "D = torch.diag(D).type(torch.float)\n",
        "inv = torch.inverse(M).type(torch.float)\n"
      ],
      "metadata": {
        "id": "QPbgDF3igzni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mul = torch.mm(torch.inverse(M),D)\n",
        "mull = torch.mm(mul,M)"
      ],
      "metadata": {
        "id": "6w4wR5L9pymJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eigue = torch.empty(20)\n",
        "eigue = torch.linalg.eig(mull)\n",
        "eigue"
      ],
      "metadata": {
        "id": "YY-kJCn_rJpo",
        "outputId": "d127964a-bf3b-4b69-de33-77d8de869813",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.return_types.linalg_eig(\n",
              "eigenvalues=tensor([ 1.0000+0.j, 20.0000+0.j,  2.0000+0.j, 19.0000+0.j, 18.0000+0.j, 17.0000+0.j,\n",
              "         3.0000+0.j,  4.0000+0.j, 16.0000+0.j,  5.0000+0.j, 15.0000+0.j,  6.0000+0.j,\n",
              "        14.0000+0.j,  7.0000+0.j,  8.0000+0.j,  9.0000+0.j, 11.0000+0.j, 10.0000+0.j,\n",
              "        13.0000+0.j, 12.0000+0.j]),\n",
              "eigenvectors=tensor([[ 3.9898e-02+0.j,  1.3182e-01+0.j, -2.5029e-01+0.j,  1.9064e-02+0.j,\n",
              "         -1.8931e-01+0.j,  1.0830e-02+0.j,  5.1461e-03+0.j, -1.0797e-01+0.j,\n",
              "          3.0513e-01+0.j, -8.7543e-02+0.j,  2.6841e-02+0.j,  9.7061e-02+0.j,\n",
              "         -2.5143e-01+0.j, -7.3488e-03+0.j,  2.9072e-01+0.j,  2.2416e-01+0.j,\n",
              "          4.2337e-01+0.j,  4.7875e-02+0.j,  2.4495e-02+0.j,  2.6145e-01+0.j],\n",
              "        [ 5.4548e-02+0.j,  1.2166e-02+0.j, -5.6422e-02+0.j,  7.8289e-02+0.j,\n",
              "          1.0763e-01+0.j, -1.3755e-01+0.j,  7.6955e-02+0.j, -1.1331e-01+0.j,\n",
              "          1.4242e-01+0.j, -4.7749e-02+0.j,  1.7967e-02+0.j, -4.8928e-02+0.j,\n",
              "         -1.5851e-01+0.j, -3.8608e-02+0.j, -8.3605e-02+0.j,  1.5170e-01+0.j,\n",
              "          4.8050e-01+0.j, -3.6084e-02+0.j,  2.2786e-02+0.j,  5.0020e-03+0.j],\n",
              "        [ 1.4810e-01+0.j,  1.1716e-01+0.j,  6.1676e-03+0.j,  1.2007e-02+0.j,\n",
              "          1.1665e-01+0.j, -1.3297e-01+0.j,  1.7930e-01+0.j, -2.4768e-01+0.j,\n",
              "          1.9785e-01+0.j, -9.1449e-02+0.j,  1.3160e-01+0.j,  1.7920e-01+0.j,\n",
              "         -2.3756e-01+0.j, -7.2372e-02+0.j,  5.2043e-01+0.j,  2.8229e-01+0.j,\n",
              "          2.7452e-01+0.j, -7.0520e-02+0.j,  9.2214e-02+0.j,  2.5664e-01+0.j],\n",
              "        [ 1.7932e-01+0.j,  3.8609e-02+0.j,  8.4432e-02+0.j, -5.5909e-02+0.j,\n",
              "          5.2241e-01+0.j, -2.8467e-01+0.j,  2.0128e-01+0.j, -2.0229e-01+0.j,\n",
              "         -2.6110e-01+0.j, -1.2865e-01+0.j,  1.3083e-01+0.j,  3.2850e-02+0.j,\n",
              "          6.9182e-02+0.j, -1.6598e-01+0.j,  5.0519e-02+0.j,  9.2457e-02+0.j,\n",
              "          1.7342e-01+0.j, -2.0130e-01+0.j,  1.2556e-01+0.j, -1.2370e-01+0.j],\n",
              "        [ 1.9382e-01+0.j,  9.0381e-02+0.j, -1.7896e-01+0.j, -1.1956e-01+0.j,\n",
              "          3.3722e-01+0.j, -1.8483e-01+0.j,  1.9232e-01+0.j, -1.5420e-01+0.j,\n",
              "         -1.3686e-01+0.j, -1.5989e-01+0.j,  1.1082e-01+0.j, -1.1196e-01+0.j,\n",
              "         -4.8562e-02+0.j, -1.7789e-01+0.j, -3.8462e-02+0.j,  3.8599e-02+0.j,\n",
              "         -5.5435e-02+0.j, -1.8322e-01+0.j,  1.2739e-01+0.j, -1.8670e-01+0.j],\n",
              "        [-3.5133e-01+0.j, -3.0968e-01+0.j,  2.4261e-01+0.j,  2.9272e-01+0.j,\n",
              "         -2.3593e-01+0.j,  2.8403e-01+0.j, -3.3639e-01+0.j,  2.9404e-01+0.j,\n",
              "          3.0904e-01+0.j,  3.0919e-01+0.j, -2.9153e-01+0.j,  3.2179e-01+0.j,\n",
              "          1.7554e-01+0.j,  3.3352e-01+0.j, -2.7477e-01+0.j, -2.9859e-01+0.j,\n",
              "          4.1448e-02+0.j,  3.6367e-01+0.j, -3.8723e-01+0.j,  2.3469e-01+0.j],\n",
              "        [-2.2123e-02+0.j,  2.8842e-02+0.j, -1.4311e-01+0.j, -4.5044e-02+0.j,\n",
              "         -1.1896e-01+0.j,  1.5494e-02+0.j,  5.2325e-02+0.j, -7.1846e-02+0.j,\n",
              "         -7.0535e-02+0.j,  2.6424e-03+0.j,  3.5789e-02+0.j, -2.0787e-01+0.j,\n",
              "         -1.7886e-01+0.j, -2.5802e-02+0.j, -4.6863e-02+0.j,  6.4997e-02+0.j,\n",
              "          9.6622e-02+0.j, -3.6996e-02+0.j,  3.9617e-02+0.j, -1.2547e-04+0.j],\n",
              "        [ 1.7758e-01+0.j,  8.3381e-02+0.j,  4.2859e-02+0.j, -1.2403e-01+0.j,\n",
              "          5.6876e-02+0.j, -1.3083e-01+0.j,  1.7663e-01+0.j, -1.6220e-01+0.j,\n",
              "         -4.3613e-02+0.j, -1.6735e-01+0.j,  1.2242e-01+0.j,  2.9256e-01+0.j,\n",
              "         -3.9183e-02+0.j, -1.1585e-01+0.j,  1.3724e-01+0.j,  2.4394e-01+0.j,\n",
              "          1.0610e-01+0.j, -1.1076e-01+0.j,  1.3494e-01+0.j,  9.5916e-02+0.j],\n",
              "        [-4.4161e-01+0.j, -5.2425e-01+0.j,  3.9183e-01+0.j,  5.1810e-01+0.j,\n",
              "         -1.1442e-01+0.j,  3.9398e-01+0.j, -4.8183e-01+0.j,  5.3566e-01+0.j,\n",
              "          3.9403e-01+0.j,  5.2844e-01+0.j, -5.6209e-01+0.j, -2.0541e-01+0.j,\n",
              "          5.0339e-01+0.j,  4.8149e-01+0.j, -4.4840e-01+0.j, -4.3498e-01+0.j,\n",
              "          9.0254e-02+0.j,  4.8369e-01+0.j, -4.8783e-01+0.j,  3.3460e-01+0.j],\n",
              "        [-1.8037e-01+0.j, -1.2335e-01+0.j,  1.4469e-01+0.j,  2.0522e-01+0.j,\n",
              "         -2.5751e-01+0.j,  1.7438e-01+0.j, -1.3228e-01+0.j,  1.0470e-01+0.j,\n",
              "          6.1062e-02+0.j,  1.5943e-01+0.j, -1.4959e-01+0.j, -6.8708e-02+0.j,\n",
              "          2.9326e-02+0.j,  1.5658e-01+0.j,  9.5320e-02+0.j, -1.1157e-01+0.j,\n",
              "         -1.8911e-01+0.j,  1.6376e-01+0.j, -1.3748e-01+0.j,  1.5451e-01+0.j],\n",
              "        [-1.0752e-01+0.j, -8.4738e-02+0.j,  9.2895e-02+0.j,  1.5804e-01+0.j,\n",
              "         -2.4066e-01+0.j,  1.5296e-01+0.j, -8.5049e-02+0.j,  1.0057e-01+0.j,\n",
              "          1.4561e-01+0.j,  1.2941e-01+0.j, -1.1990e-01+0.j,  6.5679e-01+0.j,\n",
              "         -9.5433e-02+0.j,  1.2392e-01+0.j, -8.8019e-02+0.j, -1.1179e-02+0.j,\n",
              "          2.5098e-01+0.j,  1.0310e-01+0.j, -1.6469e-01+0.j,  1.1141e-01+0.j],\n",
              "        [ 3.3005e-01+0.j,  2.3338e-01+0.j, -8.1869e-02+0.j, -3.2308e-01+0.j,\n",
              "          3.9219e-01+0.j, -3.2104e-01+0.j,  3.1240e-01+0.j, -2.7884e-01+0.j,\n",
              "         -3.6149e-01+0.j, -2.4023e-01+0.j,  3.0780e-01+0.j, -9.1952e-02+0.j,\n",
              "          1.2454e-01+0.j, -3.2242e-01+0.j, -1.1995e-01+0.j,  1.4594e-01+0.j,\n",
              "         -1.1272e-01+0.j, -3.3618e-01+0.j,  3.2444e-01+0.j, -3.5922e-01+0.j],\n",
              "        [-2.7042e-01+0.j, -1.2601e-01+0.j,  7.1283e-02+0.j,  2.8798e-01+0.j,\n",
              "         -2.5497e-01+0.j,  2.4156e-01+0.j, -1.5238e-01+0.j,  1.2307e-01+0.j,\n",
              "          3.4189e-01+0.j,  1.6736e-01+0.j, -2.0101e-01+0.j, -1.7067e-01+0.j,\n",
              "         -1.2576e-01+0.j,  2.3462e-01+0.j,  1.8576e-01+0.j, -3.6540e-02+0.j,\n",
              "          2.0227e-01+0.j,  2.1985e-01+0.j, -2.5228e-01+0.j,  2.9578e-01+0.j],\n",
              "        [-1.9774e-01+0.j, -1.4074e-01+0.j,  1.3975e-01+0.j,  2.1633e-01+0.j,\n",
              "         -1.2202e-01+0.j,  2.6040e-01+0.j, -1.2861e-01+0.j,  1.1738e-01+0.j,\n",
              "          2.3059e-01+0.j,  1.4168e-01+0.j, -1.6770e-01+0.j,  1.1596e-01+0.j,\n",
              "          4.5067e-03+0.j,  1.8524e-01+0.j,  1.0486e-01+0.j, -3.9834e-02+0.j,\n",
              "         -3.2345e-02+0.j,  1.7934e-01+0.j, -1.2549e-01+0.j,  1.6613e-01+0.j],\n",
              "        [ 2.0105e-01+0.j,  2.6788e-01+0.j, -1.7784e-01+0.j, -2.6167e-01+0.j,\n",
              "          1.3919e-02+0.j, -1.0033e-01+0.j,  1.6447e-01+0.j, -2.4329e-01+0.j,\n",
              "         -1.5859e-01+0.j, -2.2772e-01+0.j,  2.4658e-01+0.j,  2.4258e-01+0.j,\n",
              "         -2.5426e-01+0.j, -2.0976e-01+0.j,  1.2229e-01+0.j,  3.6099e-01+0.j,\n",
              "         -1.6204e-01+0.j, -2.0436e-01+0.j,  2.1633e-01+0.j, -2.0822e-01+0.j],\n",
              "        [ 2.7553e-01+0.j,  3.7605e-01+0.j, -3.4922e-01+0.j, -3.2920e-01+0.j,\n",
              "          1.6360e-01+0.j, -3.0836e-01+0.j,  3.2391e-01+0.j, -2.7291e-01+0.j,\n",
              "         -3.1408e-01+0.j, -3.1693e-01+0.j,  2.3059e-01+0.j, -2.2150e-01+0.j,\n",
              "         -3.3090e-01+0.j, -3.0724e-01+0.j,  1.1040e-01+0.j,  2.5054e-01+0.j,\n",
              "          1.1600e-02+0.j, -3.2024e-01+0.j,  3.6247e-01+0.j, -2.9338e-01+0.j],\n",
              "        [-3.0297e-01+0.j, -3.5360e-01+0.j,  4.0561e-01+0.j,  2.2899e-01+0.j,\n",
              "         -2.5499e-01+0.j,  3.0529e-01+0.j, -3.4358e-01+0.j,  3.2448e-01+0.j,\n",
              "          1.8153e-01+0.j,  3.7245e-01+0.j, -3.6739e-01+0.j,  4.2769e-02+0.j,\n",
              "          4.3622e-01+0.j,  3.2140e-01+0.j, -3.8458e-01+0.j, -3.8464e-01+0.j,\n",
              "         -3.7151e-01+0.j,  2.7444e-01+0.j, -2.2526e-01+0.j,  2.7524e-01+0.j],\n",
              "        [ 3.8466e-02+0.j,  1.8486e-03+0.j,  3.3209e-02+0.j, -5.2654e-02+0.j,\n",
              "          3.3063e-02+0.j, -6.2512e-02+0.j,  3.6172e-02+0.j, -2.6166e-02+0.j,\n",
              "         -4.8219e-02+0.j, -2.8138e-03+0.j, -3.9685e-02+0.j,  5.3521e-02+0.j,\n",
              "          5.7124e-02+0.j, -4.5213e-02+0.j,  1.3185e-01+0.j, -2.8839e-02+0.j,\n",
              "         -1.4301e-01+0.j, -4.6087e-02+0.j,  4.0818e-02+0.j, -1.5949e-01+0.j],\n",
              "        [ 1.4666e-01+0.j,  1.9368e-01+0.j, -1.2953e-01+0.j, -1.0486e-01+0.j,\n",
              "          5.2376e-02+0.j, -1.7500e-01+0.j,  1.7728e-01+0.j, -1.7972e-01+0.j,\n",
              "          9.6279e-02+0.j, -1.3911e-01+0.j,  1.2541e-01+0.j, -2.5732e-01+0.j,\n",
              "         -1.8598e-01+0.j, -1.6026e-01+0.j,  2.4263e-01+0.j,  1.3277e-01+0.j,\n",
              "          2.7591e-01+0.j, -1.4153e-01+0.j,  1.5228e-01+0.j,  3.4792e-01+0.j],\n",
              "        [ 2.3862e-01+0.j,  3.0379e-01+0.j, -5.1324e-01+0.j, -2.4529e-01+0.j,\n",
              "          1.1159e-01+0.j, -2.8092e-01+0.j,  2.4559e-01+0.j, -2.1192e-01+0.j,\n",
              "         -9.4333e-02+0.j, -2.7996e-01+0.j,  2.6222e-01+0.j, -4.4368e-02+0.j,\n",
              "         -2.9452e-01+0.j, -2.7252e-01+0.j,  8.9399e-02+0.j,  3.1406e-01+0.j,\n",
              "          1.9103e-01+0.j, -2.5446e-01+0.j,  2.5735e-01+0.j, -8.5326e-02+0.j]]))"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3- FLOPS per second"
      ],
      "metadata": {
        "id": "tmT8aLwCYe4Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate two square matrices of dimension 5000 Ã— 5000 filled with random Gaussian coefficients,\n",
        "compute their product, measure the time it takes, and estimate how many floating point products\n",
        "have been executed per second (should be in the billions or tens of billions).\n",
        "\n",
        "\n",
        "**Hint**: Use `torch.empty`, `torch.normal_`, `torch.mm`, and `time.perf_counter`"
      ],
      "metadata": {
        "id": "gMoEUAdsYmQr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from time import perf_counter"
      ],
      "metadata": {
        "id": "-_knh3alYv4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one = torch.randn(5000,5000)\n",
        "two = torch.randn(5000,5000)\n",
        "t1_start = perf_counter()\n",
        "matmul= torch.mm(one,two)\n",
        "\n",
        "t1_stop = perf_counter()\n",
        "\n",
        "\n",
        "print(\"Elapsed time:\", t1_stop, t1_start)\n",
        " \n",
        " \n",
        "print(\"Elapsed time during the whole program in seconds:\",t1_stop-t1_start)\n",
        "\n",
        "floating_point = 7500*5000\n",
        "\n",
        "\n",
        "print(\"floating point products have been executed per second:\",floating_point/(t1_stop-t1_start))\n"
      ],
      "metadata": {
        "id": "Sp8ObzlBsXUh",
        "outputId": "bf9535ae-e610-4764-fb4b-1e2426ced051",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 4082.17670752 4078.363135932\n",
            "Elapsed time during the whole program in seconds: 3.8135715879998315\n",
            "floating point products have been executed per second: 9833301.705414755\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8RBHg2FtsXKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4- Playing with strides"
      ],
      "metadata": {
        "id": "dSOjqYgsYvCP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a function `mul_row`, using python loops (and not even slicing operators), that gets a 2d tensor\n",
        "as argument, and returns a tensor of same size, whose first row is identical to the first row of the\n",
        "argument tensor, the second row is multiplied by two, the third by three, etc.\n",
        "For instance:\n",
        "\n"
      ],
      "metadata": {
        "id": "iwWUKW6lY--R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m = torch.full((4, 8), 2.0)\n",
        "m"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4Eg3UBzhcoe",
        "outputId": "5c0ed5fb-3e37-4b33-c330-6aeb4726f69c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2., 2., 2., 2., 2., 2., 2., 2.],\n",
              "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
              "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
              "        [2., 2., 2., 2., 2., 2., 2., 2.]])"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def mul_row(x):\n",
        "  # YOUR CODE HERE\n",
        "  for i in torch.arange(len(x)):\n",
        "    j = i+1\n",
        "    x[i]*=j\n",
        "  return x\n"
      ],
      "metadata": {
        "id": "0cbvd7BrhYcN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, write a second version named `mul_row_fast`, using tensor operations.\n",
        "Apply both versions to a matrix of size 1000 Ã— 400 and measure the time each takes (there should\n",
        "be more than two orders of magnitude difference).\n",
        "\n",
        "**Hint**: Use broadcasting and `torch.arange`, `torch.view`, `torch.mul`, and `time.perf_counter`."
      ],
      "metadata": {
        "id": "B6R-Q2QLZayb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t1_start = perf_counter()\n",
        "mul_row(m)\n",
        "\n",
        "t1_stop = perf_counter()\n",
        "\n",
        "\n",
        "print(\"Elapsed time:\", t1_stop, t1_start)\n",
        " \n",
        " \n",
        "print(\"Elapsed time during the whole program in seconds:\",t1_stop-t1_start)\n"
      ],
      "metadata": {
        "id": "3T1TDob5XJgV",
        "outputId": "54697052-c2ed-417d-8299-eb9826010f2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 5663.219948588 5663.219264921\n",
            "Elapsed time during the whole program in seconds: 0.000683666999975685\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def mul_row_fast(x):\n",
        "  l = torch.arange(1,len(x)+1).view(len(x),-1)\n",
        "  mat = torch.mul(x,l)\n",
        "  return mat"
      ],
      "metadata": {
        "id": "4GGGoObrXDL8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mul_row_fast(m)"
      ],
      "metadata": {
        "id": "Qg8Zh_dTXAnU",
        "outputId": "3b97c50e-388b-4085-d1d6-8911b12163ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2., 2., 2., 2., 2., 2., 2., 2.],\n",
              "        [4., 4., 4., 4., 4., 4., 4., 4.],\n",
              "        [6., 6., 6., 6., 6., 6., 6., 6.],\n",
              "        [8., 8., 8., 8., 8., 8., 8., 8.]])"
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t1_start = perf_counter()\n",
        "mul_row_fast(m)\n",
        "\n",
        "t1_stop = perf_counter()\n",
        "\n",
        "\n",
        "print(\"Elapsed time:\", t1_stop, t1_start)\n",
        " \n",
        " \n",
        "print(\"Elapsed time during the whole program in seconds:\",t1_stop-t1_start)"
      ],
      "metadata": {
        "id": "DGv4caquz_uX",
        "outputId": "edf3e425-1e07-4e38-96bc-106f1cb7ae7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time: 5692.883198356 5692.88266523\n",
            "Elapsed time during the whole program in seconds: 0.0005331259999366011\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I learnt that pytorch is very fast and its easy to use like numpy. Also, using pytorch operation is faster than using for loop."
      ],
      "metadata": {
        "id": "VgW_dYVa0YVC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "87FTmLm21Wdz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}